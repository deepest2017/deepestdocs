## Image Classification

이미지 분류에 사용하는 가장 유명한 데이터는 MNIST이고, 그 뒤를 이어 CIFAR-10, CIFAR-100, SVHN 등의 데이터가 있습니다. MNIST는 기본 중의 기본이고, 최근에는 아무리 못해도 CIFAR-10, 이미지 관련이라면 ImageNet 정도는 되어야 논문에 쓸 수 있습니다. 다양한 응용에 특화된 다양한 데이터가 있고, 음성 분야와는 다르게 거의 전부 무료로 공개되어 있습니다.

약간 오래된 벤치마크 결과가 들어 있는 사이트입니다. [Dataset Benchmarks](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)

**MNIST**

MNIST 데이터는 손으로 쓴 0부터 9까지의 숫자를 모아 놓은 데이터입니다. 한 장당 28x28 크기입니다. [MNIST](http://yann.lecun.com/exdb/mnist)

> MNIST: Modified dataset from National Institute of Standards and Technology

훈련용 데이터 60,000개와 테스트용 데이터 10,000개가 들어 있습니다. 너무 성능이 좋아져서 요즘은 거의 다 맞추기 때문에 성능의 지표로 논문에 넣기는 많이 부족하지만, 그래도 여전히 알고리즘을 테스트하고 논문의 빈칸을 채워야 할 때 가장 많이 사용하는 데이터입니다. GPU에서 훈련시키면 10 ~ 20분 내로 훈련이 끝납니다.

공식 홈페이지에서 지원하는 포맷은 바이트 형식으로, 읽어들이는 코드를 짜기가 심히 귀찮습니다. Sam roweis라는 사람이 MNIST를 matlab으로 저장해 놓은 게 있으니 그걸 쓰는걸 강력히 추천합니다. [MNIST matlab dataset](http://www.cs.nyu.edu/~roweis/data.html)

MLP같은 모델에 넣기 위해서는 처음 받은 대로 N x 784 행렬로 저장해 놓는 것이 좋지만, CNN 모델에 들어가기 위해서는 _reshape_ 를 사용해 4차원 텐서로 바꿔줘야 합니다. 이 경우 흑백 이미지로 채널(맵) 수는 1입니다.

**CIFAR-10, CIFAR-100**

CIFAR 데이터는 RGB로 된 10개/100개 사물의 사진을 모아 놓은 데이터입니다. 한 장당 32x32 크기입니다. [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html)

> CIFAR: Canadian Institute For Advanced Research

CIFAR-10에 들어 있는 사물들의 라벨은 다음과 같습니다.

> airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck

공식 홈페이지에서 Matlab 데이터를 받아 사용할 수 있습니다. 10,000개씩의 데이터가 든 5개 훈련 데이터 파일과 1개 테스트 데이터 파일을 제공합니다. 즉, 총 50,000개의 훈련 데이터와 10,000개의 테스트 데이터가 있습니다. 각 데이터는 R,G,B 채널 순서대로 펼쳐 놓은 1024개 차원씩 3072차 벡터로 저장되어 있습니다. MNIST와 마찬가지로 uint8 형식으로 저장되어 있기 때문에, 적절한 변환을 거쳐 원하는 데이터 형태로 만들어 줍니다.

**SVHN**

SVHN 데이터는 구글이 구글 지도를 만드는 과정에서 촬영한 영상에서 집들의 번호판을 찍어 놓은 32x32 크기의 RGB 데이터입니다. 번호판 전체를 보여주는 첫 번째 타입과, 각 숫자 단위로 잘라 놓은 두 번째 타입이 있습니다. 보통 SVHN이라고 하면 두 번째를 이야기합니다. [SVHN](http://ufldl.stanford.edu/housenumbers/)

> SVHN: Street View House Numbers

두 번째 타입 기준으로, 공식 홈페이지에서 Matlab 데이터를 받으면 4D 텐서로 이미 잘 저장된 73,257개 훈련 데이터와 26,032개 테스트 데이터가 들어 있습니다. 다만 텐서 축의 순서가 좀 뒤바뀌어 있기 때문에 잘 조절해야 합니다.

**ImageNet**

ImageNet은 ILSVRC 챌린지에서 사용하는 데이터입니다. [ImageNet](http://www.image-net.org/) 전 세계에서 모은 이미지들로 챌린지를 열어 누가 컴퓨터 비젼 분야에서 제일 뛰어난 기술을 갖고 있는지를 겨룹니다. 매년 새로운 승자가 등장하고, 그렇게 등장한 기술들은 거의 대부분 반드시 사용해야만 하는 기술이 되곤 합니다. 아쉽게도 2017년을 마지막으로 한다는 뉴스가 있었습니다.

1,000 종류의 1,281,167 개 데이터가 주어지고 데이터가 어떤 물체인지를 맞추는 챌린지입니다. 각 종류별 데이터의 갯수도 다릅니다. 분류 외에도 탐지(detection) 등 다른 부문도 있지만, 제일 유명한 것은 1,000 종류 분류입니다. 엄청나게 많은 데이터인데다, 전체를 합치면 200GB에 가깝습니다. 이 크기는 절대 GPU에 들어갈 수 없기 때문에 보통 특별한 방법을 써서 GPU 훈련을 시킵니다.

> ILSVRC: ImageNet Large Scale Visual Recognition Competetion

논문에서 사용하는 ImageNet 데이터는 ILSVRC 2012 의 분류 문제에 사용된 데이터입니다. 실제로 ImageNet 데이터는 저게 전부가 아니고, 훨씬 많은 전 세계에서 모은 데이터들을 모아 놓은 사이트입니다. 다만 이 중 일부를 떼서 챌린지 용으로 사용하는 것 뿐입니다. ImageNet 회원이 되면 비상업적 목적으로 원본 이미지를 다운받을 수도 있고, 이미지의 URL만 받아 불러올 수도 있습니다. 하지만 훈련을 위해서는 역시 원본 이미지가 있어야 합니다. 이미지들의 크기도 전부 다르기 때문에 전처리도 필요합니다. 

**Pascal VOC**

VOC(visual object class)는 이미지에서 특정 물체를 인식하는 데이터입니다. ImageNet과 비슷하지만 훨씬 어렵습니다. 2012년까지는 챌린지로 운영되어 왔지만 지금은 챌린지가 열리지는 않습니다. 그래도 여전히 많은 논문에서 사용합니다.

---

## Other Image Tasks

이미지 분류 쪽이 제일 활발하게 데이터를 만들고 있지만, 다른 목적으로 개발된 데이터도 많이 있습니다. 다만 이 경우 정답(label)을 사람이 만들기가 힘들어 주로 대기업에서 만든 데이터들입니다.

**MS COCO**

마이크로소프트에서 만든 이미지 인식(recognition), 분리(segmentation), 캡션 붙이기(captioning), 사람의 키포인트(keypoint) 찾기 등을 위한 데이터입니다. 대단히 많은 데이터로 구성되어 있고 MS에서 작정하고 만든 데이터입니다. 매년 챌린지가 열리고 있습니다!

**Flickr 8k, Flickr 30k**

Filckr 8k는 사진 공유 사이트 Flickr 에서 모은 8,000여 장의 이미지들에 사람이 직접 캡션을 붙여 만든 데이터로 각 캡션마다 몇 점인지 점수가 매겨져 있는 것이 특징입니다. 캡션 붙이기 과제에서 가장 많이 사용하는 데이터 중 하나입니다. 30k의 경우 더 많은 데이터와 더 복잡한 캡션이 들어 있는 확장 버전입니다.

**Other Datasets**

이미지 분류 및 기타 목적으로 사용하는 데이터 중 위에서 언급하지 않았지만 빈번히 등장하는 데이터들은 다음과 같습니다.

> NORB, Caltech101, IRIS, CelebA, CMU Face, LSUN ...

---